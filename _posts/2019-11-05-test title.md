---
layout: post
title: test title
categories : [ML,DL]
use_math: true
---
<!--밑바닥부터 시작하는 딥러닝 요약--->

밑바닥부터 시작하는 딥러닝
================
복습겸 요약 정리. 

Chapter 1 생략  
----------------  
Chapter 2 퍼셉트론  
----------------  
**퍼셉트론** : 다수의 신호를 입력으로 받아 하나의 신호를 출력.  
가장 단순한 퍼셉트론은 2 신호를 입력으로 받아 각각 가중치를 곱하고, 더한 뒤 해당값이 특정한 값(임계값.$\theta$)를 넘어설 때 1을, 아니라면 0을 출력하는 퍼셉트론이다.

가중치(weight)는 각 신호의 중요도,혹은 영향력이라고 생각할 수 있다. 첫번째 신호에 대한 가중치가 높고 두번재 신호에 대한 가중치가 낮다면 결과는 첫번째 신호의 강도에 크게 영향을 받을 것이다.

가장 간단한 퍼셉트론의 식은 다음과 같다. (w는 가중치, x는 입력신호, y는 출력신호) 

$$ y =  \begin{cases} 0 & w_{1}x_{1}+w_{2}x_{2} \leq \theta\\1 & w_{1}x_{1}+w_{2}x_{2} \geq \theta\\ \end{cases} $$
 만들었기 때문에 별거없어보이지만, 이후 적합한 weight를 자동으로 찾아내는 방법들을 언급할것이다.

$w_{1}x_{1}+w_{2}x_{2}$ 에 bias $b$를 더하여 $w_{1}x_{1}+w_{2}x_{2}+b$의 형태로 사용할 수 있다.(bias는 따로 고려하기도 하지만 weight와 묶어서 같이 weight로 표현하기도 함)
$w_{1}x_{1}+w_{2}x_{2}+b$는 선형방정식 형태이다. 따라서 weight를 조절하는 것은 $x_{1}$과 $x_{2}$를 축으로 하는 vector space에서 직선의 기울기와 bias를 조절하는 것으로 생가갈 수있다. 
그렇기에 가장 단순한 퍼셉트론의 weight를 조절하는 것으로 AND, NAND, OR같은 선형 문제는 풀 수 있지만 XOR같은 비선형 문제를 풀 수 없다.


  

이 퍼셉트론의 $w_{1}$과 $w_{2}$를 잘 조절하면 이 퍼셉트론은 AND, OR, NAND 게이트를 구현할 수 있다.  
똑같은 구조를 가진 퍼셉트론이 weight만 바꾸면 다른 함수가 된다는 것은 중요한 포인트이다.  
지금은 weight를 직접 조절해서 우리가 원하는 함수가 되도록 만들었지만 나중에는 weight가 자동으로 조절되는 방법을 소개할것이다.



chapter 3 신경망

softmax 함수
overflow를 피하기 위해 상수를 이용해서 구현(밑바닥 93)
inference 단계에서는 계산하지 않고 max를 하는게 계산비용의 이득(지수함수 계산이 비쌈)




